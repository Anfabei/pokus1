{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48295c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "idx = pd.IndexSlice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4303900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!\n"
     ]
    }
   ],
   "source": [
    "def greet_the_world():\n",
    "    return \"Hello, world!\"\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    greetings = greet_the_world()\n",
    "    print(greetings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f63c8c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    " #from pages.IES_Course import IES_Course\n",
    "#from pages.IES_Thesis import IES_Thesis\n",
    "#from pages.IES_Person import IES_Person\n",
    "\n",
    "\n",
    "class IES_Downloader:\n",
    "    '''\n",
    "    Download manager class for IES web\n",
    "    \n",
    "    It contains methods for collection of links, downloading itself and storing results\n",
    "    '''\n",
    "    def __init__(self,allowLog=True):\n",
    "        '''\n",
    "        creates IES_Downloader object with self.links, that store links to be downloaded\n",
    "        and self.people, self.courses and self.theses to store individual IES_Web-like objects\n",
    "        '''\n",
    "        self.allowLog = allowLog\n",
    "        self.links = {\n",
    "            'people':{},\n",
    "            'courses':[],\n",
    "            'theses':{}\n",
    "        }\n",
    "        self.people = []\n",
    "        self.courses = []\n",
    "        self.theses = []\n",
    "        \n",
    "        if self.allowLog:\n",
    "            print('Succesfully initialized IES Downloader')\n",
    "    \n",
    "    def getPeopleLinksForCategory(self,link,category):\n",
    "        '''\n",
    "        Downloads all person links in the specified webpage and saves it to self.links\n",
    "        '''\n",
    "        if self.allowLog:\n",
    "            print('Searching for Person-links of {} on {} ...'.format(category,link))\n",
    "        r = requests.get(link)\n",
    "        r.encoding = 'UTF-8'\n",
    "        soup = BeautifulSoup(r.text,'lxml')\n",
    "\n",
    "        self.links['people'][category] = self.getLinksByCondition(soup,'td[class=peopleTableCellName] > a')\n",
    "\n",
    "        if self.allowLog:\n",
    "            print('Found {} Person-links for {}'.format(len(self.links['people'][category]),category))\n",
    "            \n",
    "    def getThesesLinksForCategory(self,link,category):\n",
    "        '''\n",
    "        Downloads all theses-links in the specified webpage between 1994 and 2020 and saves it to self.links\n",
    "        link -- a webpage to parse from\n",
    "        category -- indicates a type of thesis\n",
    "        \n",
    "        does not return anything, but fills in self.links['theses'][category] instead\n",
    "        '''\n",
    "        if self.allowLog:\n",
    "            print('Searching for theses-links of {} on {} ...'.format(category,link))\n",
    "\n",
    "        l = []\n",
    "        for year in range(1994,2020):\n",
    "            tblLink = link + 'year/' + str(year)\n",
    "            \n",
    "            r = requests.get(tblLink)\n",
    "            soup = BeautifulSoup(r.text,'lxml')\n",
    "            l = l + ['http://ies.fsv.cuni.cz' + a['href'] for a in soup.find_all('a') if 'work' in a['href']]\n",
    "            \n",
    "        self.links['theses'][category] = l\n",
    "        if self.allowLog:\n",
    "            print('Found {} Theses-links for {}'.format(len(self.links['theses'][category]),category))\n",
    "\n",
    "    def downloadPeople(self,pause=0.5):\n",
    "        '''\n",
    "        Download all links stored in self.link['people'] and store it in self.people\n",
    "        pause -- how long to pause between requests? (in seconds)\n",
    "        tqdm -- the progress bar showing a progress of iterator\n",
    "        '''\n",
    "        if self.allowLog:\n",
    "            count = sum([len(self.links['people'][key])for key in self.links['people']])\n",
    "            print('Downloading all {} persons ...'.format(count))\n",
    "\n",
    "        for key in self.links['people']:\n",
    "            for link in tqdm(self.links['people'][key],desc=key):\n",
    "                person = IES_Person(link,key)\n",
    "                self.people.append(person)\n",
    "                time.sleep(pause)\n",
    "        if self.allowLog:\n",
    "            print('Succesfully downloaded {} persons'.format(len(self.people)))\n",
    "\n",
    "    def downloadTheses(self,pause=0.5):\n",
    "        '''\n",
    "        Download all links stored in self.link['theses'] and store it in self.theses\n",
    "        pause -- how long to pause between requests? (in seconds)\n",
    "        tqdm -- the progress bar showing a progress of iterator\n",
    "        '''\n",
    "        if self.allowLog:\n",
    "            count = sum([len(self.links['theses'][key])for key in self.links['theses']])\n",
    "            print('Downloading all {} theses ...'.format(count))\n",
    "\n",
    "        for key in self.links['theses']:\n",
    "            for link in tqdm(self.links['theses'][key],desc=key):\n",
    "                thesis = IES_Thesis(link,key)\n",
    "                self.theses.append(thesis)\n",
    "                time.sleep(pause)\n",
    "        if self.allowLog:\n",
    "            print('Succesfully downloaded {} theses'.format(len(self.theses)))\n",
    "\n",
    "    def downloadCourses(self,pause=0.5):\n",
    "        '''\n",
    "        Download all links stored in self.link['courses'] and store it in self.courses\n",
    "        pause -- how long to pause between requests? (in seconds)\n",
    "        tqdm -- the progress bar showing a progress of iterator\n",
    "        '''\n",
    "        if self.allowLog:\n",
    "            count = len(self.links['courses'])\n",
    "            print('Downloading all {} courses ...'.format(count))\n",
    "\n",
    "        for link in tqdm(self.links['courses'],desc='Courses'):\n",
    "            try:\n",
    "                course = IES_Course(link)\n",
    "                self.courses.append(course)\n",
    "                time.sleep(pause)\n",
    "            except:\n",
    "                print(f'Parsing course link {link} failed')\n",
    "                    \n",
    "        if self.allowLog:\n",
    "            print('Succesfully downloaded {} courses'.format(len(self.courses)))\n",
    "\n",
    "    \n",
    "    def getCoursesLinksFromPersons(self):\n",
    "        '''\n",
    "        In all persons stored in self.people, find all links containing substring 'syllab'\n",
    "        Exclude duplicates and store in self.links['courses']\n",
    "        '''\n",
    "        if self.allowLog:\n",
    "            print('Looking for course links in already downloaded persons  ...')\n",
    "        total_links = [person.soup.select('a[href*=syllab]') for person in self.people]\n",
    "\n",
    "        url_prefix = 'http://ies.fsv.cuni.cz/en/syllab/'\n",
    "        for person_links in total_links:\n",
    "            for link in person_links:\n",
    "                ident = link['href'].strip('/').split('/')[-1]\n",
    "                if ident:\n",
    "                    link_candidate = url_prefix + ident\n",
    "                    if link_candidate not in self.links['courses']:\n",
    "                        self.links['courses'].append(link_candidate)\n",
    "\n",
    "        if self.allowLog:\n",
    "            print('Among {} persons found {} unique courses'.format(len(self.people),len(self.links['courses'])))\n",
    "        \n",
    "    def getLinksByCondition(self,soup,cond):\n",
    "        '''\n",
    "        find all links satisfying condition cond in soup object\n",
    "        '''\n",
    "        links = soup.select(cond)\n",
    "        return ['http://ies.fsv.cuni.cz'  + l['href'] for l in links]\n",
    "    \n",
    "    def saveDFs(self):\n",
    "        dfs = {}\n",
    "        dfs['theses'] = pd.DataFrame([x.characteristics for x in self.theses])\n",
    "        dfs['courses'] = pd.DataFrame([x.characteristics for x in self.courses])\n",
    "        dfs['people'] =  pd.DataFrame([x.characteristics for x in self.people])    \n",
    "        self.dfs = dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d918de1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
